{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT_J_6B_TriviaQA-v2-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "19167576cfc94a198f8b4c4e8a090c43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3b76153f78fa43e28c782b6486dc1c17",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b86f253eafea429185381bb8e3b89efb",
              "IPY_MODEL_21f3b73848cb49c0aeb218f6a6869001"
            ]
          }
        },
        "3b76153f78fa43e28c782b6486dc1c17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b86f253eafea429185381bb8e3b89efb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e7c0ca31601f484d9098b802fbee116b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9a40d9f63ab74fd782aee896e7e8ecb0"
          }
        },
        "21f3b73848cb49c0aeb218f6a6869001": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f76cbc55ea4d42d1aae7409429e45c19",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04M/1.04M [00:05&lt;00:00, 187kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_41531902b206425394aea40b59a1b8f5"
          }
        },
        "e7c0ca31601f484d9098b802fbee116b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9a40d9f63ab74fd782aee896e7e8ecb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f76cbc55ea4d42d1aae7409429e45c19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "41531902b206425394aea40b59a1b8f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "58837aa6ab8e43b7a2bb2fa31373433c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1abf521376094803aa5aa5480421d181",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2cacdea1eec44fd5a4a5ae2a7ac9e738",
              "IPY_MODEL_3a46128bccb547ec828929808a14b92f"
            ]
          }
        },
        "1abf521376094803aa5aa5480421d181": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2cacdea1eec44fd5a4a5ae2a7ac9e738": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9c0442826cb9426aa2a27fdfdeb08ae8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c68a2139a9d46a8a8ef88e723f6ce4f"
          }
        },
        "3a46128bccb547ec828929808a14b92f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9e7c7b8447814d81a8c4643943901b48",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 2.00MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d7258c037e5f4cc7a54a9b318829d6ea"
          }
        },
        "9c0442826cb9426aa2a27fdfdeb08ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c68a2139a9d46a8a8ef88e723f6ce4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e7c7b8447814d81a8c4643943901b48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d7258c037e5f4cc7a54a9b318829d6ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dcf5deb7226d403d8458b5ab09334f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d3f012b4242e467cacb342ccc4935ecb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b3be4a924b11489fb97f1a27df9335ed",
              "IPY_MODEL_a54ddb030c3340d39109843b64c70f9b"
            ]
          }
        },
        "d3f012b4242e467cacb342ccc4935ecb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3be4a924b11489fb97f1a27df9335ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_831f334f4b0445d4b39882f57aaf7e59",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1355256,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1355256,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f05f3eb189041939f7b3a337460a6ec"
          }
        },
        "a54ddb030c3340d39109843b64c70f9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_72a74b51a88f4ce2b8887ad2155710e0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.36M/1.36M [00:04&lt;00:00, 291kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c7bb5ddd445c42d88265f4afaa884c79"
          }
        },
        "831f334f4b0445d4b39882f57aaf7e59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f05f3eb189041939f7b3a337460a6ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "72a74b51a88f4ce2b8887ad2155710e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c7bb5ddd445c42d88265f4afaa884c79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzqwNXS-9LwJ"
      },
      "source": [
        "<a href=\"http://colab.research.google.com/github/elsanns/retrieval-demo/blob/main/GPT_J_6B_TriviaQA_v2_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "This notebook is a demo of running GPT-J on TriviaQA.\n",
        "\n",
        "Adapted from: [GPT_J_6B_TriviaQA.ipynb](https://colab.research.google.com/drive/1lAbbh06PBcx6ykEBRHe0MG10CZBMQ610?usp=sharing)\n",
        "\n",
        "Links:\n",
        "\n",
        "- https://arxiv.org/pdf/1705.03551.pdf\n",
        "- http://nlp.cs.washington.edu/triviaqa/\n",
        "- https://github.com/mandarjoshi90/triviaqa\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHIJVqHsh4An"
      },
      "source": [
        "# GPT-J-6B Inference Demo\n",
        "\n",
        "Code from [GPT_J_6B_TriviaQA.ipynb](https://colab.research.google.com/drive/1lAbbh06PBcx6ykEBRHe0MG10CZBMQ610?usp=sharing)\n",
        "\n",
        "<a href=\"http://colab.research.google.com/github/kingoflolz/mesh-transformer-jax/blob/master/colab_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "This notebook demonstrates how to run the [GPT-J-6B model](https://github.com/kingoflolz/mesh-transformer-jax/#GPT-J-6B). See the link for more details about the model, including evaluation metrics and credits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CMw_dSQKfhT"
      },
      "source": [
        "## Install Dependencies\n",
        "\n",
        "First we download the model and install some dependencies. This step takes at least 5 minutes (possibly longer depending on server load).\n",
        "\n",
        "!!! **Make sure you are using a TPU runtime!** !!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7xAFw-LOYfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e509b3ef-be47-4dac-8de9-e2321c423db4"
      },
      "source": [
        "!apt install zstd\n",
        "\n",
        "# the \"slim\" version contain only bf16 weights and no optimizer parameters, which minimizes bandwidth and memory\n",
        "!time wget -c https://the-eye.eu/public/AI/GPT-J-6B/step_383500_slim.tar.zstd\n",
        "\n",
        "!time tar -I zstd -xf step_383500_slim.tar.zstd\n",
        "\n",
        "!git clone https://github.com/kingoflolz/mesh-transformer-jax.git\n",
        "!pip install -r mesh-transformer-jax/requirements.txt\n",
        "\n",
        "# jax 0.2.12 is required due to a regression with xmap in 0.2.13\n",
        "!pip install mesh-transformer-jax/ jax==0.2.12"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  zstd\n",
            "0 upgraded, 1 newly installed, 0 to remove and 40 not upgraded.\n",
            "Need to get 278 kB of archives.\n",
            "After this operation, 1,141 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 zstd amd64 1.3.3+dfsg-2ubuntu1.2 [278 kB]\n",
            "Fetched 278 kB in 1s (343 kB/s)\n",
            "Selecting previously unselected package zstd.\n",
            "(Reading database ... 160837 files and directories currently installed.)\n",
            "Preparing to unpack .../zstd_1.3.3+dfsg-2ubuntu1.2_amd64.deb ...\n",
            "Unpacking zstd (1.3.3+dfsg-2ubuntu1.2) ...\n",
            "Setting up zstd (1.3.3+dfsg-2ubuntu1.2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "--2021-07-20 09:02:32--  https://the-eye.eu/public/AI/GPT-J-6B/step_383500_slim.tar.zstd\n",
            "Resolving the-eye.eu (the-eye.eu)... 162.213.130.242\n",
            "Connecting to the-eye.eu (the-eye.eu)|162.213.130.242|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9414712325 (8.8G) [application/octet-stream]\n",
            "Saving to: ‘step_383500_slim.tar.zstd’\n",
            "\n",
            "step_383500_slim.ta 100%[===================>]   8.77G  24.5MB/s    in 3m 21s  \n",
            "\n",
            "2021-07-20 09:05:54 (44.6 MB/s) - ‘step_383500_slim.tar.zstd’ saved [9414712325/9414712325]\n",
            "\n",
            "\n",
            "real\t3m22.902s\n",
            "user\t0m5.788s\n",
            "sys\t0m23.385s\n",
            "\n",
            "real\t4m2.415s\n",
            "user\t0m37.096s\n",
            "sys\t0m29.342s\n",
            "Cloning into 'mesh-transformer-jax'...\n",
            "remote: Enumerating objects: 630, done.\u001b[K\n",
            "remote: Counting objects: 100% (281/281), done.\u001b[K\n",
            "remote: Compressing objects: 100% (103/103), done.\u001b[K\n",
            "remote: Total 630 (delta 227), reused 199 (delta 175), pack-reused 349\u001b[K\n",
            "Receiving objects: 100% (630/630), 182.79 KiB | 3.81 MiB/s, done.\n",
            "Resolving deltas: 100% (407/407), done.\n",
            "Collecting git+https://github.com/deepmind/dm-haiku (from -r mesh-transformer-jax/requirements.txt (line 10))\n",
            "  Cloning https://github.com/deepmind/dm-haiku to /tmp/pip-req-build-svwowtcp\n",
            "  Running command git clone -q https://github.com/deepmind/dm-haiku /tmp/pip-req-build-svwowtcp\n",
            "Collecting git+https://github.com/EleutherAI/lm-evaluation-harness/ (from -r mesh-transformer-jax/requirements.txt (line 11))\n",
            "  Cloning https://github.com/EleutherAI/lm-evaluation-harness/ to /tmp/pip-req-build-__m8d9k7\n",
            "  Running command git clone -q https://github.com/EleutherAI/lm-evaluation-harness/ /tmp/pip-req-build-__m8d9k7\n",
            "Requirement already satisfied: numpy~=1.19.5 in /usr/local/lib/python3.7/dist-packages (from -r mesh-transformer-jax/requirements.txt (line 1)) (1.19.5)\n",
            "Collecting transformers~=4.8.2\n",
            "  Downloading transformers-4.8.2-py3-none-any.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 5.3 MB/s \n",
            "\u001b[?25hCollecting tqdm~=4.45.0\n",
            "  Downloading tqdm-4.45.0-py2.py3-none-any.whl (60 kB)\n",
            "\u001b[K     |████████████████████████████████| 60 kB 7.4 MB/s \n",
            "\u001b[?25hCollecting setuptools~=51.3.3\n",
            "  Downloading setuptools-51.3.3-py3-none-any.whl (786 kB)\n",
            "\u001b[K     |████████████████████████████████| 786 kB 32.0 MB/s \n",
            "\u001b[?25hCollecting wandb~=0.10.22\n",
            "  Downloading wandb-0.10.33-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 42.4 MB/s \n",
            "\u001b[?25hCollecting einops~=0.3.0\n",
            "  Downloading einops-0.3.0-py2.py3-none-any.whl (25 kB)\n",
            "Collecting requests~=2.25.1\n",
            "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 6.7 MB/s \n",
            "\u001b[?25hCollecting fabric~=2.6.0\n",
            "  Downloading fabric-2.6.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting optax==0.0.6\n",
            "  Downloading optax-0.0.6-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting ray==1.4.1\n",
            "  Downloading ray-1.4.1-cp37-cp37m-manylinux2014_x86_64.whl (51.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 51.6 MB 58 kB/s \n",
            "\u001b[?25hRequirement already satisfied: jax~=0.2.12 in /usr/local/lib/python3.7/dist-packages (from -r mesh-transformer-jax/requirements.txt (line 13)) (0.2.17)\n",
            "Requirement already satisfied: Flask~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from -r mesh-transformer-jax/requirements.txt (line 14)) (1.1.4)\n",
            "Requirement already satisfied: cloudpickle~=1.3.0 in /usr/local/lib/python3.7/dist-packages (from -r mesh-transformer-jax/requirements.txt (line 15)) (1.3.0)\n",
            "Collecting tensorflow-cpu~=2.5.0\n",
            "  Downloading tensorflow_cpu-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (168.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 168.3 MB 15 kB/s \n",
            "\u001b[?25hCollecting google-cloud-storage~=1.36.2\n",
            "  Downloading google_cloud_storage-1.36.2-py2.py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart_open[gcs] in /usr/local/lib/python3.7/dist-packages (from -r mesh-transformer-jax/requirements.txt (line 18)) (5.1.0)\n",
            "Collecting func_timeout\n",
            "  Downloading func_timeout-4.3.5.tar.gz (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 2.4 MB/s \n",
            "\u001b[?25hCollecting ftfy\n",
            "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.5 MB/s \n",
            "\u001b[?25hCollecting fastapi\n",
            "  Downloading fastapi-0.66.1-py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 295 kB/s \n",
            "\u001b[?25hCollecting uvicorn\n",
            "  Downloading uvicorn-0.14.0-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.5.dev0->-r mesh-transformer-jax/requirements.txt (line 10)) (0.12.0)\n",
            "Collecting jmp>=0.0.2\n",
            "  Downloading jmp-0.0.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.5.dev0->-r mesh-transformer-jax/requirements.txt (line 10)) (0.8.9)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.5.dev0->-r mesh-transformer-jax/requirements.txt (line 10)) (3.7.4.3)\n",
            "Collecting black==20.8b1\n",
            "  Downloading black-20.8b1.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 67.6 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting best_download>=0.0.6\n",
            "  Downloading best_download-0.0.7-py3-none-any.whl (4.5 kB)\n",
            "Collecting datasets>=1.2.1\n",
            "  Downloading datasets-1.9.0-py3-none-any.whl (262 kB)\n",
            "\u001b[K     |████████████████████████████████| 262 kB 63.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.1 in /usr/local/lib/python3.7/dist-packages (from lm-eval-harness==0.0.1->-r mesh-transformer-jax/requirements.txt (line 11)) (7.1.2)\n",
            "Collecting scikit-learn>=0.24.1\n",
            "  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 53 kB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from lm-eval-harness==0.0.1->-r mesh-transformer-jax/requirements.txt (line 11)) (1.9.0+cu102)\n",
            "Collecting sqlitedict==1.6.0\n",
            "  Downloading sqlitedict-1.6.0.tar.gz (29 kB)\n",
            "Collecting pytablewriter==0.58.0\n",
            "  Downloading pytablewriter-0.58.0-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 6.3 MB/s \n",
            "\u001b[?25hCollecting sacrebleu==1.5.0\n",
            "  Downloading sacrebleu-1.5.0-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting pycountry==20.7.3\n",
            "  Downloading pycountry-20.7.3.tar.gz (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 66.6 MB/s \n",
            "\u001b[?25hCollecting numexpr==2.7.2\n",
            "  Downloading numexpr-2.7.2-cp37-cp37m-manylinux2010_x86_64.whl (471 kB)\n",
            "\u001b[K     |████████████████████████████████| 471 kB 68.7 MB/s \n",
            "\u001b[?25hCollecting lm_dataformat==0.0.19\n",
            "  Downloading lm_dataformat-0.0.19-py3-none-any.whl (5.4 kB)\n",
            "Collecting pytest==6.2.3\n",
            "  Downloading pytest-6.2.3-py3-none-any.whl (280 kB)\n",
            "\u001b[K     |████████████████████████████████| 280 kB 74.1 MB/s \n",
            "\u001b[?25hCollecting pybind11==2.6.2\n",
            "  Downloading pybind11-2.6.2-py2.py3-none-any.whl (191 kB)\n",
            "\u001b[K     |████████████████████████████████| 191 kB 78.9 MB/s \n",
            "\u001b[?25hCollecting tqdm-multiprocess==0.0.11\n",
            "  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
            "Collecting zstandard==0.15.2\n",
            "  Downloading zstandard-0.15.2-cp37-cp37m-manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 68.3 MB/s \n",
            "\u001b[?25hCollecting jsonlines==2.0.0\n",
            "  Downloading jsonlines-2.0.0-py3-none-any.whl (6.3 kB)\n",
            "Collecting mock==4.0.3\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Collecting openai==0.6.4\n",
            "  Downloading openai-0.6.4.tar.gz (159 kB)\n",
            "\u001b[K     |████████████████████████████████| 159 kB 79.4 MB/s \n",
            "\u001b[?25hCollecting chex>=0.0.4\n",
            "  Downloading chex-0.0.8-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax==0.0.6->-r mesh-transformer-jax/requirements.txt (line 9)) (0.1.69+cuda110)\n",
            "Collecting opencensus\n",
            "  Downloading opencensus-0.7.13-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 71.1 MB/s \n",
            "\u001b[?25hCollecting aioredis\n",
            "  Downloading aioredis-1.3.1-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.9 MB/s \n",
            "\u001b[?25hCollecting pydantic>=1.8\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 71.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray==1.4.1->-r mesh-transformer-jax/requirements.txt (line 12)) (3.13)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 62.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray==1.4.1->-r mesh-transformer-jax/requirements.txt (line 12)) (3.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray==1.4.1->-r mesh-transformer-jax/requirements.txt (line 12)) (3.0.12)\n",
            "Collecting py-spy>=0.2.0\n",
            "  Downloading py_spy-0.3.7-py2.py3-none-manylinux1_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 70.3 MB/s \n",
            "\u001b[?25hCollecting redis>=3.5.0\n",
            "  Downloading redis-3.5.3-py2.py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 552 kB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting aiohttp-cors\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting gpustat\n",
            "  Downloading gpustat-0.6.0.tar.gz (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray==1.4.1->-r mesh-transformer-jax/requirements.txt (line 12)) (2.6.0)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray==1.4.1->-r mesh-transformer-jax/requirements.txt (line 12)) (0.11.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray==1.4.1->-r mesh-transformer-jax/requirements.txt (line 12)) (1.0.2)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray==1.4.1->-r mesh-transformer-jax/requirements.txt (line 12)) (1.34.1)\n",
            "Collecting pathspec<1,>=0.6\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from black==20.8b1->lm-eval-harness==0.0.1->-r mesh-transformer-jax/requirements.txt (line 11)) (1.4.4)\n",
            "Collecting regex>=2020.1.8\n",
            "  Downloading regex-2021.7.6-cp37-cp37m-manylinux2014_x86_64.whl (721 kB)\n",
            "\u001b[K     |████████████████████████████████| 721 kB 63.4 MB/s \n",
            "\u001b[?25hCollecting typed-ast>=1.4.0\n",
            "  Downloading typed_ast-1.4.3-cp37-cp37m-manylinux1_x86_64.whl (743 kB)\n",
            "\u001b[K     |████████████████████████████████| 743 kB 68.8 MB/s \n",
            "\u001b[?25hCollecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: toml>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from black==20.8b1->lm-eval-harness==0.0.1->-r mesh-transformer-jax/requirements.txt (line 11)) (0.10.2)\n",
            "Collecting ujson\n",
            "  Downloading ujson-4.0.2-cp37-cp37m-manylinux1_x86_64.whl (179 kB)\n",
            "\u001b[K     |████████████████████████████████| 179 kB 79.9 MB/s \n",
            "\u001b[?25hCollecting mbstrdecoder<2,>=1.0.0\n",
            "  Downloading mbstrdecoder-1.0.1-py3-none-any.whl (7.8 kB)\n",
            "Collecting tabledata<2,>=1.1.3\n",
            "  Downloading tabledata-1.2.0-py3-none-any.whl (11 kB)\n",
            "Collecting msgfy<1,>=0.1.0\n",
            "  Downloading msgfy-0.1.0-py3-none-any.whl (4.3 kB)\n",
            "Collecting DataProperty<2,>=0.50.0\n",
            "  Downloading DataProperty-0.52.0-py3-none-any.whl (26 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5\n",
            "  Downloading tcolorpy-0.1.1-py3-none-any.whl (8.0 kB)\n",
            "Collecting typepy[datetime]<2,>=1.1.1\n",
            "  Downloading typepy-1.2.0-py3-none-any.whl (31 kB)\n",
            "Collecting pathvalidate<3,>=2.3.0\n",
            "  Downloading pathvalidate-2.4.1-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytest==6.2.3->lm-eval-harness==0.0.1->-r mesh-transformer-jax/requirements.txt (line 11)) (21.0)\n",
            "Collecting pluggy<1.0.0a1,>=0.12\n",
            "  Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from pytest==6.2.3->lm-eval-harness==0.0.1->-r mesh-transformer-jax/requirements.txt (line 11)) (1.10.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest==6.2.3->lm-eval-harness==0.0.1->-r mesh-transformer-jax/requirements.txt (line 11)) (4.6.1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.7/dist-packages (from pytest==6.2.3->lm-eval-harness==0.0.1->-r mesh-transformer-jax/requirements.txt (line 11)) (1.1.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from pytest==6.2.3->lm-eval-harness==0.0.1->-r mesh-transformer-jax/requirements.txt (line 11)) (21.2.0)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 65.9 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 65.4 MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb~=0.10.22->-r mesh-transformer-jax/requirements.txt (line 5)) (2.3)\n",
            "Collecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb~=0.10.22->-r mesh-transformer-jax/requirements.txt (line 5)) (2.8.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb~=0.10.22->-r mesh-transformer-jax/requirements.txt (line 5)) (5.4.8)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb~=0.10.22->-r mesh-transformer-jax/requirements.txt (line 5)) (1.15.0)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "  Downloading sentry_sdk-1.3.0-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 70.8 MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 73.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests~=2.25.1->-r mesh-transformer-jax/requirements.txt (line 7)) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests~=2.25.1->-r mesh-transformer-jax/requirements.txt (line 7)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests~=2.25.1->-r mesh-transformer-jax/requirements.txt (line 7)) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests~=2.25.1->-r mesh-transformer-jax/requirements.txt (line 7)) (2.10)\n",
            "Collecting invoke<2.0,>=1.3\n",
            "  Downloading invoke-1.6.0-py3-none-any.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 76.5 MB/s \n",
            "\u001b[?25hCollecting paramiko>=2.4\n",
            "  Downloading paramiko-2.7.2-py2.py3-none-any.whl (206 kB)\n",
            "\u001b[K     |████████████████████████████████| 206 kB 77.5 MB/s \n",
            "\u001b[?25hCollecting pathlib2\n",
            "  Downloading pathlib2-2.3.6-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax~=0.2.12->-r mesh-transformer-jax/requirements.txt (line 13)) (3.3.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1.2->-r mesh-transformer-jax/requirements.txt (line 14)) (1.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1.2->-r mesh-transformer-jax/requirements.txt (line 14)) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1.2->-r mesh-transformer-jax/requirements.txt (line 14)) (1.1.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu~=2.5.0->-r mesh-transformer-jax/requirements.txt (line 16)) (3.1.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu~=2.5.0->-r mesh-transformer-jax/requirements.txt (line 16)) (0.4.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu~=2.5.0->-r mesh-transformer-jax/requirements.txt (line 16)) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu~=2.5.0->-r mesh-transformer-jax/requirements.txt (line 16)) (1.12)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu~=2.5.0->-r mesh-transformer-jax/requirements.txt (line 16)) (0.36.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu~=2.5.0->-r mesh-transformer-jax/requirements.txt (line 16)) (0.2.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu~=2.5.0->-r mesh-transformer-jax/requirements.txt (line 16)) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu~=2.5.0->-r mesh-transformer-jax/requirements.txt (line 16)) (2.5.0)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu~=2.5.0->-r mesh-transformer-jax/requirements.txt (line 16)) (2.5.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu~=2.5.0->-r mesh-transformer-jax/requirements.txt (line 16)) (1.1.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu~=2.5.0->-r mesh-transformer-jax/requirements.txt (line 16)) (1.6.3)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu~=2.5.0->-r mesh-transformer-jax/requirements.txt (line 16)) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage~=1.36.2->-r mesh-transformer-jax/requirements.txt (line 17)) (1.32.1)\n",
            "Collecting google-resumable-media<2.0dev,>=1.2.0\n",
            "  Downloading google_resumable_media-1.3.1-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting google-cloud-core<2.0dev,>=1.4.1\n",
            "  Downloading google_cloud_core-1.7.1-py2.py3-none-any.whl (28 kB)\n",
            "Collecting rehash\n",
            "  Downloading rehash-1.0.0-py2.py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax==0.0.6->-r mesh-transformer-jax/requirements.txt (line 9)) (0.11.1)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax==0.0.6->-r mesh-transformer-jax/requirements.txt (line 9)) (0.1.6)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->lm-eval-harness==0.0.1->-r mesh-transformer-jax/requirements.txt (line 11)) (0.3.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->lm-eval-harness==0.0.1->-r mesh-transformer-jax/requirements.txt (line 11)) (1.1.5)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 78.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->lm-eval-harness==0.0.1->-r mesh-transformer-jax/requirements.txt (line 11)) (3.0.0)\n",
            "Collecting fsspec>=2021.05.0\n",
            "  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 77.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->lm-eval-harness==0.0.1->-r mesh-transformer-jax/requirements.txt (line 11)) (0.70.12.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
            "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage~=1.36.2->-r mesh-transformer-jax/requirements.txt (line 17)) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage~=1.36.2->-r mesh-transformer-jax/requirements.txt (line 17)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage~=1.36.2->-r mesh-transformer-jax/requirements.txt (line 17)) (4.7.2)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage~=1.36.2->-r mesh-transformer-jax/requirements.txt (line 17)) (1.26.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage~=1.36.2->-r mesh-transformer-jax/requirements.txt (line 17)) (2018.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage~=1.36.2->-r mesh-transformer-jax/requirements.txt (line 17)) (1.53.0)\n",
            "Collecting google-crc32c<2.0dev,>=1.0\n",
            "  Downloading google_crc32c-1.1.2-cp37-cp37m-manylinux2014_x86_64.whl (38 kB)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=1.2.0->google-cloud-storage~=1.36.2->-r mesh-transformer-jax/requirements.txt (line 17)) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=1.2.0->google-cloud-storage~=1.36.2->-r mesh-transformer-jax/requirements.txt (line 17)) (2.20)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow-cpu~=2.5.0->-r mesh-transformer-jax/requirements.txt (line 16)) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest==6.2.3->lm-eval-harness==0.0.1->-r mesh-transformer-jax/requirements.txt (line 11)) (3.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->optax==0.0.6->-r mesh-transformer-jax/requirements.txt (line 9)) (1.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask~=1.1.2->-r mesh-transformer-jax/requirements.txt (line 14)) (2.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytest==6.2.3->lm-eval-harness==0.0.1->-r mesh-transformer-jax/requirements.txt (line 11)) (2.4.7)\n",
            "Collecting bcrypt>=3.1.3\n",
            "  Downloading bcrypt-3.2.0-cp36-abi3-manylinux2010_x86_64.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.5\n",
            "  Downloading cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 67.6 MB/s \n",
            "\u001b[?25hCollecting pynacl>=1.0.1\n",
            "  Downloading PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961 kB)\n",
            "\u001b[K     |████████████████████████████████| 961 kB 67.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.11.0->google-cloud-storage~=1.36.2->-r mesh-transformer-jax/requirements.txt (line 17)) (0.4.8)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.1->lm-eval-harness==0.0.1->-r mesh-transformer-jax/requirements.txt (line 11)) (1.0.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-cpu~=2.5.0->-r mesh-transformer-jax/requirements.txt (line 16)) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-cpu~=2.5.0->-r mesh-transformer-jax/requirements.txt (line 16)) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-cpu~=2.5.0->-r mesh-transformer-jax/requirements.txt (line 16)) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-cpu~=2.5.0->-r mesh-transformer-jax/requirements.txt (line 16)) (0.6.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow-cpu~=2.5.0->-r mesh-transformer-jax/requirements.txt (line 16)) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow-cpu~=2.5.0->-r mesh-transformer-jax/requirements.txt (line 16)) (3.1.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->-r mesh-transformer-jax/requirements.txt (line 20)) (0.2.5)\n",
            "Collecting starlette==0.14.2\n",
            "  Downloading starlette-0.14.2-py3-none-any.whl (60 kB)\n",
            "\u001b[K     |████████████████████████████████| 60 kB 6.7 MB/s \n",
            "\u001b[?25hCollecting asgiref>=3.3.4\n",
            "  Downloading asgiref-3.4.1-py3-none-any.whl (25 kB)\n",
            "Collecting h11>=0.8\n",
            "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[K     |████████████████████████████████| 294 kB 72.4 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[K     |████████████████████████████████| 142 kB 77.5 MB/s \n",
            "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
            "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
            "Collecting hiredis\n",
            "  Downloading hiredis-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray==1.4.1->-r mesh-transformer-jax/requirements.txt (line 12)) (7.352.0)\n",
            "Collecting blessings>=1.6\n",
            "  Downloading blessings-1.7-py3-none-any.whl (18 kB)\n",
            "Collecting opencensus-context==0.1.2\n",
            "  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\n",
            "Building wheels for collected packages: dm-haiku, lm-eval-harness, black, openai, pycountry, sqlitedict, subprocess32, func-timeout, ftfy, gpustat, pathtools\n",
            "  Building wheel for dm-haiku (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dm-haiku: filename=dm_haiku-0.0.5.dev0-py3-none-any.whl size=531847 sha256=706a68b792895dc0b8d937d4be1115febe5aa1e7a31f79e1556f756fb2c05b0e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4jw_6137/wheels/06/28/69/ebaac5b2435641427299f29d88d005fb4e2627f4a108f0bdbc\n",
            "  Building wheel for lm-eval-harness (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lm-eval-harness: filename=lm_eval_harness-0.0.1-py3-none-any.whl size=100852 sha256=47d7f8ace3799e10ca112fae6a65b99fb645d795cb7b0750bf67f0947a9985c5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4jw_6137/wheels/35/22/ec/71da337686fde904ec27f675d1bf73c4f253c48a6174d822b0\n",
            "  Building wheel for black (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for black: filename=black-20.8b1-py3-none-any.whl size=124195 sha256=2faa77632fefc28c19f881c6c809f9a38fa64b0fa0b0c7d55c62ea3c953a8afa\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/85/79/f3af8daaf8037c0bf14beb3b7a1511a39b6e6902ca2aaf494e\n",
            "  Building wheel for openai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.6.4-py3-none-any.whl size=172215 sha256=c988169f5de1d21d7453ae5a13c05e08125812c928bc1c5873b3e3d8d0fdf3ef\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/c4/02/aa519fe2aaf97a9bba197a8585182c8c07802760351afdb64a\n",
            "  Building wheel for pycountry (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycountry: filename=pycountry-20.7.3-py2.py3-none-any.whl size=10746883 sha256=1712a2bb890dd84699e8c1145fe1bbc9a1fb8f53c1325d10f29cc1764b294a38\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/e8/3f/120ccc1ff7541c108bc5d656e2a14c39da0d824653b62284c6\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-py3-none-any.whl size=14712 sha256=912797da85827fce76547e59805f135179b54024222177003ca56fe276c0f733\n",
            "  Stored in directory: /root/.cache/pip/wheels/58/dd/2c/0a57aadf6a7f26bec0af66d742c50af74d11967780f0bb7a7d\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=b67e5990a14bb664e06498f813fcfea494367473e40b653edc225a03370f0a2f\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
            "  Building wheel for func-timeout (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for func-timeout: filename=func_timeout-4.3.5-py3-none-any.whl size=15096 sha256=6d36aaec234dd4fd0d43db7f13f26dc90dfe5e071f4bfc530159f44fe62ab158\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/b5/a5/67c4364c354e141f5a1bd3ec568126f77877ab7554cf5af8cb\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41934 sha256=e423023c9db0bcb5295e12e986319a7c67fe1332faf8d8c72f0471f7dad54944\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n",
            "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-0.6.0-py3-none-any.whl size=12617 sha256=4763141860818bb699d6caba3bfb99101721a5c805794000b3666f52de5e40c8\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/67/af/f1ad15974b8fd95f59a63dbf854483ebe5c7a46a93930798b8\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=6966acf30173be69e32a9dfd12f960848fcef63f7a821915880ec1018ecf6dc9\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built dm-haiku lm-eval-harness black openai pycountry sqlitedict subprocess32 func-timeout ftfy gpustat pathtools\n",
            "Installing collected packages: mbstrdecoder, typepy, setuptools, requests, multidict, yarl, tqdm, smmap, regex, google-crc32c, DataProperty, async-timeout, zstandard, xxhash, ujson, typed-ast, tokenizers, threadpoolctl, tcolorpy, tabledata, sacremoses, rehash, pynacl, portalocker, pluggy, pathvalidate, pathspec, opencensus-context, mypy-extensions, msgfy, jsonlines, huggingface-hub, hiredis, google-resumable-media, google-cloud-core, gitdb, fsspec, cryptography, colorama, blessings, bcrypt, aiohttp, transformers, tqdm-multiprocess, subprocess32, starlette, sqlitedict, shortuuid, sentry-sdk, scikit-learn, sacrebleu, redis, pytest, pytablewriter, pydantic, pycountry, pybind11, py-spy, pathtools, pathlib2, paramiko, opencensus, openai, numexpr, mock, lm-dataformat, jmp, invoke, h11, gpustat, google-cloud-storage, GitPython, docker-pycreds, datasets, configparser, chex, black, best-download, asgiref, aioredis, aiohttp-cors, wandb, uvicorn, tensorflow-cpu, ray, optax, lm-eval-harness, func-timeout, ftfy, fastapi, fabric, einops, dm-haiku\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.2.0\n",
            "    Uninstalling setuptools-57.2.0:\n",
            "      Successfully uninstalled setuptools-57.2.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Attempting uninstall: google-resumable-media\n",
            "    Found existing installation: google-resumable-media 0.4.1\n",
            "    Uninstalling google-resumable-media-0.4.1:\n",
            "      Successfully uninstalled google-resumable-media-0.4.1\n",
            "  Attempting uninstall: google-cloud-core\n",
            "    Found existing installation: google-cloud-core 1.0.3\n",
            "    Uninstalling google-cloud-core-1.0.3:\n",
            "      Successfully uninstalled google-cloud-core-1.0.3\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "  Attempting uninstall: numexpr\n",
            "    Found existing installation: numexpr 2.7.3\n",
            "    Uninstalling numexpr-2.7.3:\n",
            "      Successfully uninstalled numexpr-2.7.3\n",
            "  Attempting uninstall: google-cloud-storage\n",
            "    Found existing installation: google-cloud-storage 1.18.1\n",
            "    Uninstalling google-cloud-storage-1.18.1:\n",
            "      Successfully uninstalled google-cloud-storage-1.18.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.25.1 which is incompatible.\n",
            "google-cloud-bigquery 1.21.0 requires google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1, but you have google-resumable-media 1.3.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed DataProperty-0.52.0 GitPython-3.1.18 aiohttp-3.7.4.post0 aiohttp-cors-0.7.0 aioredis-1.3.1 asgiref-3.4.1 async-timeout-3.0.1 bcrypt-3.2.0 best-download-0.0.7 black-20.8b1 blessings-1.7 chex-0.0.8 colorama-0.4.4 configparser-5.0.2 cryptography-3.4.7 datasets-1.9.0 dm-haiku-0.0.5.dev0 docker-pycreds-0.4.0 einops-0.3.0 fabric-2.6.0 fastapi-0.66.1 fsspec-2021.7.0 ftfy-6.0.3 func-timeout-4.3.5 gitdb-4.0.7 google-cloud-core-1.7.1 google-cloud-storage-1.36.2 google-crc32c-1.1.2 google-resumable-media-1.3.1 gpustat-0.6.0 h11-0.12.0 hiredis-2.0.0 huggingface-hub-0.0.12 invoke-1.6.0 jmp-0.0.2 jsonlines-2.0.0 lm-dataformat-0.0.19 lm-eval-harness-0.0.1 mbstrdecoder-1.0.1 mock-4.0.3 msgfy-0.1.0 multidict-5.1.0 mypy-extensions-0.4.3 numexpr-2.7.2 openai-0.6.4 opencensus-0.7.13 opencensus-context-0.1.2 optax-0.0.6 paramiko-2.7.2 pathlib2-2.3.6 pathspec-0.9.0 pathtools-0.1.2 pathvalidate-2.4.1 pluggy-0.13.1 portalocker-2.3.0 py-spy-0.3.7 pybind11-2.6.2 pycountry-20.7.3 pydantic-1.8.2 pynacl-1.4.0 pytablewriter-0.58.0 pytest-6.2.3 ray-1.4.1 redis-3.5.3 regex-2021.7.6 rehash-1.0.0 requests-2.25.1 sacrebleu-1.5.0 sacremoses-0.0.45 scikit-learn-0.24.2 sentry-sdk-1.3.0 setuptools-51.3.3 shortuuid-1.0.1 smmap-4.0.0 sqlitedict-1.6.0 starlette-0.14.2 subprocess32-3.5.4 tabledata-1.2.0 tcolorpy-0.1.1 tensorflow-cpu-2.5.0 threadpoolctl-2.2.0 tokenizers-0.10.3 tqdm-4.45.0 tqdm-multiprocess-0.0.11 transformers-4.8.2 typed-ast-1.4.3 typepy-1.2.0 ujson-4.0.2 uvicorn-0.14.0 wandb-0.10.33 xxhash-2.0.2 yarl-1.6.3 zstandard-0.15.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Processing ./mesh-transformer-jax\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting jax==0.2.12\n",
            "  Downloading jax-0.2.12.tar.gz (590 kB)\n",
            "\u001b[K     |████████████████████████████████| 590 kB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from jax==0.2.12) (1.19.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax==0.2.12) (0.12.0)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.7/dist-packages (from jax==0.2.12) (3.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->jax==0.2.12) (1.15.0)\n",
            "Building wheels for collected packages: mesh-transformer, jax\n",
            "  Building wheel for mesh-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mesh-transformer: filename=mesh_transformer-0.0.0-py3-none-any.whl size=24001 sha256=e5e7c02e0a367936c88594a25d8740637ececa521426dc8a5a75b4b3111f1b7e\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/bd/89/b1f6b2f3d6b938d0c5812ee97756a1afd32521bea293543863\n",
            "  Building wheel for jax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jax: filename=jax-0.2.12-py3-none-any.whl size=682484 sha256=42a47da8969750e45e92f5725cdd8c546bc046305dc60e2df4f7c41a39c349f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/4d/e5/73eec5070b77f25664c67bd793d4eb97f41bbf9be7afafd15e\n",
            "Successfully built mesh-transformer jax\n",
            "Installing collected packages: mesh-transformer, jax\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.2.17\n",
            "    Uninstalling jax-0.2.17:\n",
            "      Successfully uninstalled jax-0.2.17\n",
            "Successfully installed jax-0.2.12 mesh-transformer-0.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO1UXepF-0Uq"
      },
      "source": [
        "## Setup Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ex0qJgaueZtJ"
      },
      "source": [
        "import os\n",
        "import requests \n",
        "from jax.config import config\n",
        "\n",
        "colab_tpu_addr = os.environ['COLAB_TPU_ADDR'].split(':')[0]\n",
        "url = f'http://{colab_tpu_addr}:8475/requestversion/tpu_driver0.1_dev20210607'\n",
        "requests.post(url)\n",
        "\n",
        "# The following is required to use TPU Driver as JAX's backend.\n",
        "config.FLAGS.jax_xla_backend = \"tpu_driver\"\n",
        "config.FLAGS.jax_backend_target = \"grpc://\" + os.environ['COLAB_TPU_ADDR']"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIgUVdFLe4A8"
      },
      "source": [
        "Sometimes the next step errors for some reason, just run it again ¯\\\\\\_(ツ)\\_/¯"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A5IGYSaeze3"
      },
      "source": [
        "import time\n",
        "\n",
        "import jax\n",
        "from jax.experimental import maps\n",
        "import numpy as np\n",
        "import optax\n",
        "import transformers\n",
        "\n",
        "from mesh_transformer.checkpoint import read_ckpt\n",
        "from mesh_transformer.sampling import nucleaus_sample\n",
        "from mesh_transformer.transformer_shard import CausalTransformer"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAgKq-X2kmba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169,
          "referenced_widgets": [
            "19167576cfc94a198f8b4c4e8a090c43",
            "3b76153f78fa43e28c782b6486dc1c17",
            "b86f253eafea429185381bb8e3b89efb",
            "21f3b73848cb49c0aeb218f6a6869001",
            "e7c0ca31601f484d9098b802fbee116b",
            "9a40d9f63ab74fd782aee896e7e8ecb0",
            "f76cbc55ea4d42d1aae7409429e45c19",
            "41531902b206425394aea40b59a1b8f5",
            "58837aa6ab8e43b7a2bb2fa31373433c",
            "1abf521376094803aa5aa5480421d181",
            "2cacdea1eec44fd5a4a5ae2a7ac9e738",
            "3a46128bccb547ec828929808a14b92f",
            "9c0442826cb9426aa2a27fdfdeb08ae8",
            "7c68a2139a9d46a8a8ef88e723f6ce4f",
            "9e7c7b8447814d81a8c4643943901b48",
            "d7258c037e5f4cc7a54a9b318829d6ea",
            "dcf5deb7226d403d8458b5ab09334f10",
            "d3f012b4242e467cacb342ccc4935ecb",
            "b3be4a924b11489fb97f1a27df9335ed",
            "a54ddb030c3340d39109843b64c70f9b",
            "831f334f4b0445d4b39882f57aaf7e59",
            "1f05f3eb189041939f7b3a337460a6ec",
            "72a74b51a88f4ce2b8887ad2155710e0",
            "c7bb5ddd445c42d88265f4afaa884c79"
          ]
        },
        "outputId": "13f249f7-e9a6-469d-bb5e-8669808e2297"
      },
      "source": [
        "params = {\n",
        "  \"layers\": 28,\n",
        "  \"d_model\": 4096,\n",
        "  \"n_heads\": 16,\n",
        "  \"n_vocab\": 50400,\n",
        "  \"norm\": \"layernorm\",\n",
        "  \"pe\": \"rotary\",\n",
        "  \"pe_rotary_dims\": 64,\n",
        "\n",
        "  \"seq\": 2048,\n",
        "  \"cores_per_replica\": 8,\n",
        "  \"per_replica_batch\": 1,\n",
        "}\n",
        "\n",
        "per_replica_batch = params[\"per_replica_batch\"]\n",
        "cores_per_replica = params[\"cores_per_replica\"]\n",
        "seq = params[\"seq\"]\n",
        "\n",
        "\n",
        "params[\"sampler\"] = nucleaus_sample\n",
        "\n",
        "# here we \"remove\" the optimizer parameters from the model (as we don't need them for inference)\n",
        "params[\"optimizer\"] = optax.scale(0)\n",
        "\n",
        "mesh_shape = (jax.device_count() // cores_per_replica, cores_per_replica)\n",
        "devices = np.array(jax.devices()).reshape(mesh_shape)\n",
        "\n",
        "maps.thread_resources.env = maps.ResourceEnv(maps.Mesh(devices, ('dp', 'mp')))\n",
        "\n",
        "tokenizer = transformers.GPT2TokenizerFast.from_pretrained('gpt2')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19167576cfc94a198f8b4c4e8a090c43",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58837aa6ab8e43b7a2bb2fa31373433c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dcf5deb7226d403d8458b5ab09334f10",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355256.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFgRkUgfiNdA"
      },
      "source": [
        "Here we create the network and load the parameters from the downloaded files. Expect this to take around 5 minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwNETD2Uk8nu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40ed3ca7-b87a-429d-e783-4a45b6e2b282"
      },
      "source": [
        "total_batch = per_replica_batch * jax.device_count() // cores_per_replica\n",
        "\n",
        "network = CausalTransformer(params)\n",
        "\n",
        "network.state = read_ckpt(network.state, \"step_383500/\", devices.shape[1])\n",
        "\n",
        "network.state = network.move_xmap(network.state, np.zeros(cores_per_replica))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/jax/experimental/maps.py:412: UserWarning: xmap is an experimental feature and probably has bugs!\n",
            "  warn(\"xmap is an experimental feature and probably has bugs!\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "key shape (8, 2)\n",
            "in shape (1, 2048)\n",
            "dp 1\n",
            "mp 8\n",
            "Total parameters: 6053381344\n",
            "read from disk/gcs in 41.2798s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-eT7Sw6if4J"
      },
      "source": [
        "## Run Model\n",
        "\n",
        "Finally, we are ready to infer with the model! The first sample takes around a minute due to compilation, but after that it should only take about 10 seconds per sample.\n",
        "\n",
        "Feel free to mess with the different sampling parameters (top_p and temp), as well as the length of the generations (gen_len, causes a recompile when changed).\n",
        "\n",
        "You can also change other things like per_replica_batch in the previous cells to change how many generations are done in parallel. A larger batch has higher latency but higher throughput when measured in tokens generated/s. This is useful for doing things like best-of-n cherry picking.\n",
        "\n",
        "*Tip for best results: Make sure your prompt does not have any trailing spaces, which tend to confuse the model due to the BPE tokenization used during training.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSQ4TTabl4z8"
      },
      "source": [
        "# allow text wrapping in generated output: https://stackoverflow.com/a/61401455\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVzs2TYlvYeX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "8321f03a-88a2-48bf-a3ba-938ca30ce21d"
      },
      "source": [
        "def infer(context, top_p=0.9, temp=1.0, gen_len=512):\n",
        "    tokens = tokenizer.encode(context)\n",
        "\n",
        "    provided_ctx = len(tokens)\n",
        "    pad_amount = seq - provided_ctx\n",
        "\n",
        "    padded_tokens = np.pad(tokens, ((pad_amount, 0),)).astype(np.uint32)\n",
        "    batched_tokens = np.array([padded_tokens] * total_batch)\n",
        "    length = np.ones(total_batch, dtype=np.uint32) * len(tokens)\n",
        "\n",
        "    start = time.time()\n",
        "    output = network.generate(batched_tokens, length, gen_len, {\"top_p\": np.ones(total_batch) * top_p, \"temp\": np.ones(total_batch) * temp})\n",
        "\n",
        "    samples = []\n",
        "    decoded_tokens = output[1][0]\n",
        "\n",
        "    for o in decoded_tokens[:, :, 0]:\n",
        "      samples.append(f\"\\033[1m{context}\\033[0m{tokenizer.decode(o)}\")\n",
        "\n",
        "    print(f\"completion done in {time.time() - start:06}s\")\n",
        "    return samples\n",
        "\n",
        "print(infer(\"\"\"Question: What is the capital of Germany?\n",
        "Answer: \"\"\", gen_len=32)[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "completion done in 47.4418842792511s\n",
            "\u001b[1mQuestion: What is the capital of Germany?\n",
            "Answer: \u001b[0m Berlin.\n",
            "I say , the capital of Germany is Berlin.\n",
            "1. Is my answer correct?\n",
            "2. What if Berlin is not the capital\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvlAK6RbCJYg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "9855b971-b9a6-4a7c-a123-c768d6b907df"
      },
      "source": [
        "top_p = 0.1 \n",
        "temp = 0.1\n",
        "\n",
        "context = \"\"\"Question: What is the capital of Germany?\n",
        "Answer:\"\"\"\n",
        "\n",
        "print(infer(top_p=top_p, temp=temp, gen_len=32, context=context)[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "completion done in 1.110990047454834s\n",
            "\u001b[1mQuestion: What is the capital of Germany?\n",
            "Answer:\u001b[0m Berlin.\n",
            "Question: What is the capital of Germany?\n",
            "Answer: Berlin.\n",
            "Question: What is the capital of Germany?\n",
            "Answer: Berlin.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaFp02qFr2Xq"
      },
      "source": [
        "context = \"\"\"Question: What is the capital of France?\n",
        "Answer:\"\"\"\n",
        "\n",
        "print(infer(top_p=top_p, temp=temp, gen_len=32, context=context)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tm8VOx6Br4xo"
      },
      "source": [
        "context = \"\"\"Question: Who is the current US president?\n",
        "Answer:\"\"\"\n",
        "\n",
        "print(infer(top_p=top_p, temp=temp, gen_len=32, context=context)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9qOJQl8r9oh"
      },
      "source": [
        "context = \"\"\"Question: Who was the US president in 1998?\n",
        "Answer:\"\"\"\n",
        "\n",
        "print(infer(top_p=top_p, temp=temp, gen_len=32, context=context)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4CFCd51sDXw"
      },
      "source": [
        "context = \"\"\"Context: Joe Biden is the current US president.\n",
        "Question: Who is the current US president?\n",
        "Answer:\"\"\"\n",
        "\n",
        "print(infer(top_p=temp, temp=temp, gen_len=32, context=context)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy_ErMxvsP4d"
      },
      "source": [
        "context = \"\"\"Question: Who is the current US president?\n",
        "Background: Joe Biden is the current president of the United States.\n",
        "Answer:\"\"\"\n",
        "\n",
        "print(infer(top_p=top_p, temp=temp, gen_len=32, context=context)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfMYTsNrtb3Z"
      },
      "source": [
        "context = \"\"\"Question: Who is the current US president?\n",
        "Background: Joseph Robinette Biden Jr. is an American politician who is the 46th and current president of the United States. \n",
        "Answer:\"\"\"\n",
        "\n",
        "print(infer(top_p=top_p, temp=temp, gen_len=32, context=context)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEPpskiztkLo"
      },
      "source": [
        "context = \"\"\"Background: Joseph Robinette Biden Jr. is an American politician who is the 46th and current president of the United States. \n",
        "Question: Who is the current US president?\n",
        "Answer:\"\"\"\n",
        "\n",
        "print(infer(top_p=top_p, temp=temp, gen_len=32, context=context)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcRs83Jttlle"
      },
      "source": [
        "context = \"\"\"Background: Joseph Robinette Biden Jr. is an American politician who is the 46th and current president of the United States. Question: Who is the current US president?\n",
        "Answer:\"\"\"\n",
        "\n",
        "print(infer(top_p=top_p, temp=temp, gen_len=32, context=context)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbjJ0Tn9tutr"
      },
      "source": [
        "context = \"\"\"Background: Joseph Robinette Biden Jr. is an American politician who is the 46th and current president of the United States. Question: Who is the current US president? Answer:\"\"\"\n",
        "\n",
        "print(infer(top_p=top_p, temp=temp, gen_len=32, context=context)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I2M2xHotyTw"
      },
      "source": [
        "context = \"\"\"Background: Donald John Trump (born June 14, 1946) is the 45th and current president of the United States. Before entering politics, he was a businessman and television personality. Question: Who is the current US president? Answer:\"\"\"\n",
        "\n",
        "print(infer(top_p=top_p, temp=temp, gen_len=32, context=context)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sbuzxoc_ujrQ"
      },
      "source": [
        "context = \"\"\"Question: What is the newest Star Wars movie? Answer:\"\"\"\n",
        "\n",
        "print(infer(top_p=top_p, temp=temp, gen_len=32, context=context)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8NqUwqdvJB4"
      },
      "source": [
        "context = \"\"\"Question: Who has written The Mandalorian? Answer:\"\"\"\n",
        "\n",
        "print(infer(top_p=top_p, temp=temp, gen_len=32, context=context)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR5dxFzzuzL3"
      },
      "source": [
        "context = \"\"\"Background: The Mandalorian is an American space Western television series created by Jon Favreau for the streaming service Disney+. It is the first live-action series in the Star Wars franchise, beginning five years after the events of Return of the Jedi (1983). Question: Who has written The Mandalorian? Answer:\"\"\"\n",
        "\n",
        "print(infer(top_p=top_p, temp=temp, gen_len=32, context=context)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZOccJWAvdhR"
      },
      "source": [
        "context = \"\"\"Question: Who directed the 2020 movie BLACK BOX? Answer:\"\"\"\n",
        "print(infer(top_p=top_p, temp=temp, gen_len=32, context=context)[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QYDm8p9vueo"
      },
      "source": [
        "context = \"\"\"Background: Black Box is a 2020 American horror film directed by Emmanuel Osei-Kuffour Jr. and written by Emmanuel Osei-Kuffour Jr. and Stephen Herman. The film stars Mamoudou Athie, Phylicia Rashad, Amanda Christine, Tosin Morohunfola and Troy James. Jason Blum serves as an executive producer under his Blumhouse Television banner. \n",
        "Question: Who directed the 2020 movie BLACK BOX? \n",
        "Answer:\"\"\"\n",
        "print(infer(top_p=top_p, temp=temp, gen_len=32, context=context)[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srCNcEZLwDFI"
      },
      "source": [
        "context = \"\"\"Question: How many people wrote the 2020 movie BLACK BOX? \n",
        "Answer:\"\"\"\n",
        "print(infer(top_p=top_p, temp=temp, gen_len=32, context=context)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cxChW6-v7O3"
      },
      "source": [
        "context = \"\"\"Background: Black Box is a 2020 American horror film directed by Emmanuel Osei-Kuffour Jr. and written by Emmanuel Osei-Kuffour Jr. and Stephen Herman. The film stars Mamoudou Athie, Phylicia Rashad, Amanda Christine, Tosin Morohunfola and Troy James. Jason Blum serves as an executive producer under his Blumhouse Television banner. \n",
        "Based on the previous paragraph, what is the answer to \"How many people wrote the 2020 movie BLACK BOX?\" \"\"\"\n",
        "print(infer(top_p=top_p, temp=temp, gen_len=32, context=context)[0])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-4rKhyU4PZO"
      },
      "source": [
        "# TriviaQA dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MGZ9hWy9ZK1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "7fe37d00-f0b8-458f-e247-6bad7ec7b7ff"
      },
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Download sample data from a temporary repo\n",
        "% cd /\n",
        "! git clone https://github.com/elsanns/retrieval-demo.git"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/\n",
            "Cloning into 'retrieval-demo'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 21 (delta 8), reused 14 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (21/21), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m9cWjld9dLd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "e81d2611-1c62-4d9e-8caa-33bae9f69e5e"
      },
      "source": [
        "data_file = 'retrieval-demo/triviaqa/samples/verified-web-dev.json'\n",
        "with open(data_file) as f:\n",
        "    dataset_json = json.load(f)\n",
        "\n",
        "# print(data_json)\n",
        "print(dataset_json.keys())\n",
        "print(dataset_json['Data'][0].keys())\n",
        "\n",
        "# Subset of samples used in the demo\n",
        "sample_json = [x for x in dataset_json['Data'] if len(x['SearchResults']) == 1]\n",
        "sample_json = [x for x in sample_json if 'MatchedWikiEntityName' in x['Answer'].keys()]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['Data', 'Domain', 'Split', 'VerifiedEval', 'Version'])\n",
            "dict_keys(['Answer', 'EntityPages', 'Question', 'QuestionId', 'QuestionPartOfVerifiedEval', 'QuestionSource', 'QuestionVerifiedEvalAttempt', 'SearchResults'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erY8WcGB4Zbg"
      },
      "source": [
        "# Templates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muc_UxD24WOM"
      },
      "source": [
        "Examples of context data sources"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmvvNt-94a97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "2ee852c0-b7b1-48c5-ec08-19da5e6fb2ef"
      },
      "source": [
        "sample_no = 0\n",
        "print(sample_json[sample_no]['Question'])\n",
        "print('---------------------------------------')\n",
        "print(sample_json[sample_no]['SearchResults'][0]['Description'])\n",
        "print(sample_json[sample_no]['SearchResults'][0]['Title'])\n",
        "print(sample_json[sample_no]['SearchResults'][0]['Filename'])\n",
        "# print(sample_json[sample_no]['EntityPages']['FileName'])\n",
        "print('---------------------------------------')\n",
        "sample_json[sample_no]['SearchResults']"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Rita Coolidge sang the title song for which Bond film?\n",
            "---------------------------------------\n",
            "... Rita Coolidge Performing The title track to the JAMES BOND film OCTOPUSSY. Clip from THE VAL DOONICAN MUSIC SHOW 1983 Featuring Rita Coolidge ... HIGH ...\n",
            "RITA COOLIDGE ALL TIME HIGH James Bond 007 OCTOPUSSY The ...\n",
            "158/158_2486.txt\n",
            "---------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Description': '... Rita Coolidge Performing The title track to the JAMES BOND film OCTOPUSSY. Clip from THE VAL DOONICAN MUSIC SHOW 1983 Featuring Rita Coolidge ... HIGH ...',\n",
              "  'DocPartOfVerifiedEval': True,\n",
              "  'DocVerifiedEvalAttempt': True,\n",
              "  'Filename': '158/158_2486.txt',\n",
              "  'HumanAnswer': 'OCTOPUSSY',\n",
              "  'Rank': 0,\n",
              "  'Title': 'RITA COOLIDGE ALL TIME HIGH James Bond 007 OCTOPUSSY The ...',\n",
              "  'Url': 'http://www.youtube.com/watch?v=CQ2rD2ZTCB0'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs37uFVN4b5h"
      },
      "source": [
        "Sample templates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "mDh2heRH4hIv",
        "outputId": "ee26f79e-24b1-4b18-ab4c-d36da137a02b"
      },
      "source": [
        "from jinja2 import Template\n",
        "\n",
        "templates_str = {\n",
        "    'template_1': \"Background: {{ SearchResults[0]['Description'] }} Question: {{ Question }}\",\n",
        "    'template_2': \"Question: {{ Question }}, Evidence: {{ SearchResults[0]['Description'] }}\"\n",
        "}\n",
        "\n",
        "templates = {template_name: Template(template_text) for \\\n",
        "             template_name, template_text in templates_str.items()}\n",
        "\n",
        "inputs_json = sample_json[0:10]\n",
        "\n",
        "inputs = [(template_name, sample['QuestionId'], \n",
        "           templates[template_name].render(sample)) for\n",
        "          template_name in templates for sample in inputs_json]\n",
        "aux = list(zip(*inputs))\n",
        "\n",
        "inputs_df = pd.DataFrame({'template': aux[0],\n",
        "                          'question_id': aux[1],\n",
        "                          'input': aux[2]})\n",
        "\n",
        "# pd.set_option(\"max_colwidth\", 100)\n",
        "inputs_df.sort_values(by=['question_id']).head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>template</th>\n",
              "      <th>question_id</th>\n",
              "      <th>input</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>template_1</td>\n",
              "      <td>tc_1007</td>\n",
              "      <td>Background: ... Kiefer Sutherland, Lou Diamond Phillips, Christian Slater. ... Born Today; Celeb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>template_2</td>\n",
              "      <td>tc_1007</td>\n",
              "      <td>Question: Who was born first, Kiefer Sutherland or Christian Slater?, Evidence: ... Kiefer Suthe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>template_1</td>\n",
              "      <td>tc_1020</td>\n",
              "      <td>Background: When they debuted at the Monterey Pop Festival in 1967, Hendrix set his guitar on fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>template_2</td>\n",
              "      <td>tc_1020</td>\n",
              "      <td>Question: Who set fire to his guitar at the Monterey Pop festival in 19676?, Evidence: When they...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>template_1</td>\n",
              "      <td>tc_1156</td>\n",
              "      <td>Background: Murder on the Orient Express movie YIFY ... Swedish: subtitle Murder on the Orient E...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      template  ...                                                                                                input\n",
              "3   template_1  ...  Background: ... Kiefer Sutherland, Lou Diamond Phillips, Christian Slater. ... Born Today; Celeb...\n",
              "13  template_2  ...  Question: Who was born first, Kiefer Sutherland or Christian Slater?, Evidence: ... Kiefer Suthe...\n",
              "4   template_1  ...  Background: When they debuted at the Monterey Pop Festival in 1967, Hendrix set his guitar on fi...\n",
              "14  template_2  ...  Question: Who set fire to his guitar at the Monterey Pop festival in 19676?, Evidence: When they...\n",
              "5   template_1  ...  Background: Murder on the Orient Express movie YIFY ... Swedish: subtitle Murder on the Orient E...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "550baI6x1-Ss"
      },
      "source": [
        "Optionally, save templates to a file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFWMj92l1_5A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6c581e1f-2873-4995-97bf-d2a251a4efce"
      },
      "source": [
        "import yaml\n",
        "import os\n",
        "\n",
        "\n",
        "def save_templates(new_templates, file_name):\n",
        "    with open(file_name, 'w+') as f:    \n",
        "        yaml.dump(new_templates, f)  \n",
        "\n",
        "def load_templates(file_name):\n",
        "    if os.path.isfile(file_name):\n",
        "        with open(file_name, 'r') as f:\n",
        "            return yaml.safe_load(f)   \n",
        "    return None \n",
        "\n",
        "def add_templates(new_templates, file_name, replace=True):\n",
        "    existing_templates = load_templates(file_name)\n",
        "    if existing_templates is not None:\n",
        "        common_keys = existing_templates.keys() & new_templates.keys()\n",
        "        if len(common_keys) > 0 and not replace:\n",
        "            raise RuntimeError(\"Conflictiong keys: \",common_keys)    \n",
        "    else:\n",
        "        existing_templates = {} \n",
        "\n",
        "    existing_templates.update(new_templates)\n",
        "    save_templates(existing_templates, file_name)    \n",
        "\n",
        "#file_name = '<FILE_NAME>'\n",
        "#templates_str = load_templates(file_name)\n",
        "#save_templates(templates_str, file_name)\n",
        "#add_templates(templates_str, file_name, replace=True)  "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4_CeD1uuCyX"
      },
      "source": [
        "# Run on TriviaQA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOFMjx1ouUSF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e56f9d06-0a7c-43f5-9b0f-e974a90e0fd3"
      },
      "source": [
        "def infer_triviaqa(context, top_p=0.9, temp=1.0, gen_len=512):\n",
        "    tokens = tokenizer.encode(context)\n",
        "\n",
        "    provided_ctx = len(tokens)\n",
        "    pad_amount = seq - provided_ctx\n",
        "\n",
        "    padded_tokens = np.pad(tokens, ((pad_amount, 0),)).astype(np.uint32)\n",
        "    batched_tokens = np.array([padded_tokens] * total_batch)\n",
        "    length = np.ones(total_batch, dtype=np.uint32) * len(tokens)\n",
        "\n",
        "    start = time.time()\n",
        "    output = network.generate(batched_tokens, length, gen_len, {\"top_p\": np.ones(total_batch) * top_p, \"temp\": np.ones(total_batch) * temp})\n",
        "\n",
        "    samples_raw = []\n",
        "    samples = []\n",
        "    decoded_tokens = output[1][0]\n",
        "\n",
        "    for o in decoded_tokens[:, :, 0]:\n",
        "      decoded_o = tokenizer.decode(o)\n",
        "      samples_raw.append(decoded_o)\n",
        "      samples.append(f\"\\033[1m{context}\\033[0m{decoded_o}\")\n",
        "\n",
        "    print(f\"completion done in {time.time() - start:06}s\")\n",
        "    return samples_raw[0], samples[0]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZYmAXbv60y9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733
        },
        "outputId": "356a414a-cfd4-4313-98d0-36ad8c0cca2d"
      },
      "source": [
        "top_p = 0.1 \n",
        "temp = 0.1\n",
        "gen_length = 32\n",
        "\n",
        "outputs = [(template, question_id, input, \\\n",
        "            infer_triviaqa(input, top_p=top_p, temp=temp, \\\n",
        "                           gen_len=gen_length)[0]) for template, question_id, input in inputs]\n",
        "\n",
        "aux = list(zip(*outputs))\n",
        "\n",
        "outputs_df = pd.DataFrame({'template': aux[0],\n",
        "                           'question_id': aux[1],\n",
        "                           'input': aux[2],\n",
        "                           'output': aux[3]})\n",
        "outputs_df.sort_values(by=['question_id']).head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "completion done in 1.1101150512695312s\n",
            "completion done in 1.1083815097808838s\n",
            "completion done in 1.1078987121582031s\n",
            "completion done in 1.1012403964996338s\n",
            "completion done in 1.105710744857788s\n",
            "completion done in 1.1259407997131348s\n",
            "completion done in 1.118351697921753s\n",
            "completion done in 1.1199641227722168s\n",
            "completion done in 1.1089677810668945s\n",
            "completion done in 1.101353406906128s\n",
            "completion done in 1.1022577285766602s\n",
            "completion done in 1.1130142211914062s\n",
            "completion done in 1.1094396114349365s\n",
            "completion done in 1.1075098514556885s\n",
            "completion done in 1.113586187362671s\n",
            "completion done in 1.0976669788360596s\n",
            "completion done in 1.1023828983306885s\n",
            "completion done in 1.114588975906372s\n",
            "completion done in 1.1150715351104736s\n",
            "completion done in 1.1140875816345215s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>template</th>\n",
              "      <th>question_id</th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>template_1</td>\n",
              "      <td>tc_1007</td>\n",
              "      <td>Background: ... Kiefer Sutherland, Lou Diamond Phillips, Christian Slater. ... Born Today; Celeb...</td>\n",
              "      <td>... Answer: Kiefer Sutherland was born first....\\n\\nQuestion:... Kiefer Sutherland, Lou Diamond ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>template_2</td>\n",
              "      <td>tc_1007</td>\n",
              "      <td>Question: Who was born first, Kiefer Sutherland or Christian Slater?, Evidence: ... Kiefer Suthe...</td>\n",
              "      <td>\\n\\nQuestion: Who was born first, Kiefer Sutherland or Christian Slater?, Evidence:... Kiefer Su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>template_1</td>\n",
              "      <td>tc_1020</td>\n",
              "      <td>Background: When they debuted at the Monterey Pop Festival in 1967, Hendrix set his guitar on fi...</td>\n",
              "      <td>Answer: Jimi Hendrix.\\n\\nQuestion: Who set fire to his guitar at the Monterey Pop festival in 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>template_2</td>\n",
              "      <td>tc_1020</td>\n",
              "      <td>Question: Who set fire to his guitar at the Monterey Pop festival in 19676?, Evidence: When they...</td>\n",
              "      <td>\\n\\nQuestion: Who set fire to his guitar at the Monterey Pop festival in 19676?, Evidence: When ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>template_1</td>\n",
              "      <td>tc_1156</td>\n",
              "      <td>Background: Murder on the Orient Express movie YIFY ... Swedish: subtitle Murder on the Orient E...</td>\n",
              "      <td>Answer: Ingrid Bergman.\\n\\nQuestion: Which Swedish actress won the Best Supporting Actress Osca...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      template  ...                                                                                               output\n",
              "3   template_1  ...  ... Answer: Kiefer Sutherland was born first....\\n\\nQuestion:... Kiefer Sutherland, Lou Diamond ...\n",
              "13  template_2  ...  \\n\\nQuestion: Who was born first, Kiefer Sutherland or Christian Slater?, Evidence:... Kiefer Su...\n",
              "4   template_1  ...   Answer: Jimi Hendrix.\\n\\nQuestion: Who set fire to his guitar at the Monterey Pop festival in 1...\n",
              "14  template_2  ...  \\n\\nQuestion: Who set fire to his guitar at the Monterey Pop festival in 19676?, Evidence: When ...\n",
              "5   template_1  ...   Answer: Ingrid Bergman.\\n\\nQuestion: Which Swedish actress won the Best Supporting Actress Osca...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7-rLgPCuGox"
      },
      "source": [
        "# Evaluate on TriviaQA\n",
        "\n",
        "Adapted from:\n",
        "https://github.com/mandarjoshi90/triviaqa/blob/master/evaluation/triviaqa_evaluation.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zUXGkLjHlrX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "bf38cf71-a3e3-48fe-8498-85f5a7f7e040"
      },
      "source": [
        "% cd /\n",
        "! git clone https://github.com/mandarjoshi90/triviaqa.git\n",
        "% cd triviaqa"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/\n",
            "Cloning into 'triviaqa'...\n",
            "remote: Enumerating objects: 67, done.\u001b[K\n",
            "remote: Total 67 (delta 0), reused 0 (delta 0), pack-reused 67\u001b[K\n",
            "Unpacking objects: 100% (67/67), done.\n",
            "/triviaqa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACpB1vlWekXo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f101bd80-2c19-421d-d6c5-6fe652ae2d14"
      },
      "source": [
        "from evaluation.triviaqa_evaluation import (\n",
        "    get_ground_truths,\n",
        "    metric_max_over_ground_truths,\n",
        "    exact_match_score,\n",
        "    f1_score)\n",
        "\n",
        "\n",
        "def get_answer_for_qid(dataset_json, qid):\n",
        "    return [x['Answer'] for x in dataset_json['Data'] if x['QuestionId']==qid][0]\n",
        "\n",
        "\n",
        "def get_ground_truths_for_qid(dataset_json, qid):\n",
        "    answer = get_answer_for_qid(dataset_json, qid)\n",
        "    return get_ground_truths(answer)\n",
        "\n",
        "\n",
        "def contains_answer_score(prediction, ground_truth):\n",
        "    return ground_truth.lower() in prediction.lower()\n",
        "\n",
        "\n",
        "def get_ground_truths_all(dataset_json, predictions):\n",
        "    return {qid: get_ground_truths_for_qid(dataset_json, qid) \\\n",
        "            for qid in predictions.keys()}\n",
        "\n",
        "\n",
        "template_names = set(x[0] for x in outputs)\n",
        "outputs_eval_json = {}\n",
        "\n",
        "for template in template_names:\n",
        "    outputs_eval_json[template] = {}\n",
        "    for x in outputs:\n",
        "        if x[0] == template:\n",
        "            outputs_eval_json[template][x[1]] = x[3]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPiRFkr8hJLD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "e624669d-9bdf-4aad-d420-69dddc6462d1"
      },
      "source": [
        "scores = []\n",
        "\n",
        "for template, predictions in outputs_eval_json.items():\n",
        "    ground_truths_all = get_ground_truths_all(dataset_json, predictions)\n",
        "\n",
        "    for question_id, prediction in predictions.items():\n",
        "        ground_truths = get_ground_truths_all(dataset_json, predictions)[question_id]\n",
        "        exact_match = metric_max_over_ground_truths(exact_match_score, \n",
        "                                                    prediction, \n",
        "                                                    ground_truths)\n",
        "        f1 = metric_max_over_ground_truths(f1_score, prediction, ground_truths)\n",
        "        contains_answer = metric_max_over_ground_truths(contains_answer_score, \n",
        "                                                        prediction, \n",
        "                                                        ground_truths)\n",
        "        scores.append((template, question_id, exact_match, f1, contains_answer))\n",
        "\n",
        "df_cols = {col_name: vals for col_name, vals in \\\n",
        "           zip(['template', 'question_id', 'exact_match', 'f1', 'contains_answer'], \n",
        "               list(zip(*scores)))}\n",
        "df_scores = pd.DataFrame(df_cols)\n",
        "\n",
        "df_scores"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>template</th>\n",
              "      <th>question_id</th>\n",
              "      <th>exact_match</th>\n",
              "      <th>f1</th>\n",
              "      <th>contains_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>template_1</td>\n",
              "      <td>tc_69</td>\n",
              "      <td>False</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>template_1</td>\n",
              "      <td>tc_261</td>\n",
              "      <td>False</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>template_1</td>\n",
              "      <td>tc_280</td>\n",
              "      <td>False</td>\n",
              "      <td>0.235294</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>template_1</td>\n",
              "      <td>tc_1007</td>\n",
              "      <td>False</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>template_1</td>\n",
              "      <td>tc_1020</td>\n",
              "      <td>False</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>template_1</td>\n",
              "      <td>tc_1156</td>\n",
              "      <td>False</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>template_1</td>\n",
              "      <td>tc_1516</td>\n",
              "      <td>False</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>template_1</td>\n",
              "      <td>tc_1535</td>\n",
              "      <td>False</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>template_1</td>\n",
              "      <td>tc_1542</td>\n",
              "      <td>False</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>template_1</td>\n",
              "      <td>tc_1826</td>\n",
              "      <td>False</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>template_2</td>\n",
              "      <td>tc_69</td>\n",
              "      <td>False</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>template_2</td>\n",
              "      <td>tc_261</td>\n",
              "      <td>False</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>template_2</td>\n",
              "      <td>tc_280</td>\n",
              "      <td>False</td>\n",
              "      <td>0.210526</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>template_2</td>\n",
              "      <td>tc_1007</td>\n",
              "      <td>False</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>template_2</td>\n",
              "      <td>tc_1020</td>\n",
              "      <td>False</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>template_2</td>\n",
              "      <td>tc_1156</td>\n",
              "      <td>False</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>template_2</td>\n",
              "      <td>tc_1516</td>\n",
              "      <td>False</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>template_2</td>\n",
              "      <td>tc_1535</td>\n",
              "      <td>False</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>template_2</td>\n",
              "      <td>tc_1542</td>\n",
              "      <td>False</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>template_2</td>\n",
              "      <td>tc_1826</td>\n",
              "      <td>False</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      template question_id  exact_match        f1  contains_answer\n",
              "0   template_1       tc_69        False  0.240000             True\n",
              "1   template_1      tc_261        False  0.071429            False\n",
              "2   template_1      tc_280        False  0.235294             True\n",
              "3   template_1     tc_1007        False  0.222222             True\n",
              "4   template_1     tc_1020        False  0.190476             True\n",
              "5   template_1     tc_1156        False  0.181818             True\n",
              "6   template_1     tc_1516        False  0.250000             True\n",
              "7   template_1     tc_1535        False  0.100000             True\n",
              "8   template_1     tc_1542        False  0.100000            False\n",
              "9   template_1     tc_1826        False  0.095238             True\n",
              "10  template_2       tc_69        False  0.181818            False\n",
              "11  template_2      tc_261        False  0.080000            False\n",
              "12  template_2      tc_280        False  0.210526             True\n",
              "13  template_2     tc_1007        False  0.200000             True\n",
              "14  template_2     tc_1020        False  0.000000            False\n",
              "15  template_2     tc_1156        False  0.000000            False\n",
              "16  template_2     tc_1516        False  0.272727             True\n",
              "17  template_2     tc_1535        False  0.000000            False\n",
              "18  template_2     tc_1542        False  0.000000            False\n",
              "19  template_2     tc_1826        False  0.095238             True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JeYgfxL0NIA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "aec36c3c-86e0-4ab7-952a-3d62c1eb89d0"
      },
      "source": [
        "% cd /"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}